{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/D-Barradas/RAPIDS_HPO/blob/main/notebooks/HPO_cuML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciMBynkBaCLF"
      },
      "source": [
        "# HPO with dask-ml and cuml\n",
        "\n",
        "## Introduction\n",
        "\n",
        "&emsp; &emsp; &emsp; [Hyperparameter optimization](https://cloud.google.com/ai-platform/training/docs/hyperparameter-tuning-overview) is the task of picking the values for the hyperparameters of the model that provide the optimal results for the problem, as measured on a specific test dataset. This is often a crucial step and can help boost the model accuracy when done correctly. Cross-validation is often used to more accurately estimate the performance of the models in the search process. Cross-validation is the method of splitting the training set into complementary subsets and performing training on one of the subsets, then predicting the models performance on the other. This is a potential indication of how the model will generalise to data it has not seen before.\n",
        "\n",
        "Despite its theoretical importance, HPO has been difficult to implement in practical applications because of the resources needed to run so many distinct training jobs.\n",
        "\n",
        "The two approaches that we will be exploring in this notebook are :\n",
        "\n",
        "\n",
        "#### 1. GridSearch\n",
        "\n",
        "&emsp; &emsp; &emsp; As the name suggests, the \"search\" is done over each possible combination in a grid of parameters that the user provides. The user must manually define this grid.. For each parameter that needs to be tuned, a set of values are given and the final grid search is performed with tuple having one element from each set, thus resulting in a Catersian Product of the elements.\n",
        "\n",
        "&emsp; &emsp; &emsp;For example, assume we want to perform HPO on XGBoost. For simplicity lets tune only `n_estimators` and `max_depth`\n",
        "\n",
        "&emsp; &emsp; &emsp;`n_estimators: [50, 100, 150]`\n",
        "\n",
        "&emsp; &emsp; &emsp;`max_depth: [6, 7, ,8]`\n",
        "    \n",
        "&emsp; &emsp; &emsp; The grid search will take place over |n_estimators| x |max_depth| which is 3 x 3 = 9. As you have probably guessed, the grid size grows rapidly as the number of parameters and their search space increases.\n",
        "\n",
        "#### 2. RandomSearch\n",
        "\n",
        "\n",
        "&emsp; &emsp; &emsp; [Random Search](http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf) replaces the exhaustive nature of the search from before with a random selection of parameters over the specified space. This method can outperform GridSearch in cases where the number of parameters affecting the model's performance is small (low-dimension optimization problems). Since this does not pick every tuple from the cartesian product, it tends to yield results faster, and the performance can be comparable to that of the Grid Search approach. It's worth keeping in mind that the random nature of this search means, the results with each run might differ.\n",
        "\n",
        "Some of the other methods used for HPO include:\n",
        "\n",
        "1. Bayesian Optimization\n",
        "\n",
        "2. Gradient-based Optimization\n",
        "\n",
        "3. Evolutionary Optimization\n",
        "\n",
        "To learn more about HPO, some papers are linked to at the end of the notebook for further reading.\n",
        "\n",
        "Now that we have a basic understanding of what HPO is, let's discuss what we wish to achieve with this demo. The aim of this notebook is to show the importance of hyper parameter optimisation and the performance of dask-ml GPU for xgboost and cuML-RF.\n",
        "\n",
        "For this demo, we will be using the [Airline dataset](http://kt.ijs.si/elena_ikonomovska/data.html). The aim of the problem is to predict the arrival delay. It has about 116 million entries with 13 attributes that are used to determine the delay for a given airline. We have modified this problem to serve as a binary classification problem to determine if the airline will be delayed (True) or not.\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHGD6r__aCLH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import cudf\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.model_selection import KFold, ParameterSampler, RandomizedSearchCV, GridSearchCV\n",
        "\n",
        "\n",
        "from cuml.ensemble import RandomForestClassifier\n",
        "from cuml.model_selection import train_test_split\n",
        "from cuml.metrics import accuracy_score\n",
        "\n",
        "import time\n",
        "import os\n",
        "from urllib.request import urlretrieve\n",
        "import gzip\n",
        "import glob\n",
        "from cuml.experimental.hyperopt_utils import plotting_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpnkwoHcaCLH"
      },
      "source": [
        "### Spinning up a CUDA Cluster\n",
        "\n",
        "We start a local cluster and keep it ready for running distributed tasks with dask.\n",
        "\n",
        "\n",
        "[LocalCUDACluster](https://github.com/rapidsai/dask-cuda) launches one Dask worker for each GPU in the current systems. It's developed as a part of the RAPIDS project.\n",
        "Learn More:\n",
        "- [Setting up Dask](https://docs.dask.org/en/latest/setup.html)\n",
        "- [Dask Client](https://distributed.dask.org/en/latest/client.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount the google Drive\n"
      ],
      "metadata": {
        "id": "5XalFHZjdDyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQr3DXqadC8O",
        "outputId": "98b053d6-556e-4397-f50f-ddd735062440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIqKQqcBaCLI"
      },
      "source": [
        "## Setup parameters  \n",
        "NOTE: You must execute the download_data notebook before. It migth take up to 15 minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjBitq_ZaCLI"
      },
      "outputs": [],
      "source": [
        "\n",
        "num_rows = 2500000  # number of rows to be used in this notebook\n",
        "\n",
        "# the parrent dir path is important to place the data and results in the correct flder\n",
        "# parent_dir = \"/\".join(os.getcwd().split(\"/\")[:-1])\n",
        "parent_dir = \"/content/drive/MyDrive/\"\n",
        "\n",
        "data_dir = os.path.join(parent_dir, \"data\", \"airline-data\")\n",
        "\n",
        "orc_name = os.path.join(data_dir, \"airline-data\" + str(num_rows) + \".orc\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKUaIASeaCLJ"
      },
      "source": [
        "## Check the data is downloaded , otherwise execute the download_data.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsxBQCOFaCLJ"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset():\n",
        "    try:\n",
        "        if os.path.isfile(orc_name):\n",
        "            df = cudf.read_orc(orc_name)\n",
        "            df = df.drop(\"index\",axis=1)\n",
        "                # encode categoricals as numeric\n",
        "            for col in df.select_dtypes([\"object\"]).columns:\n",
        "                df[col] = df[col].astype(\"category\").cat.codes.astype(np.int32)\n",
        "\n",
        "            # cast all columns to int32\n",
        "            for col in df.columns:\n",
        "                df[col] = df[col].astype(np.float32)  # needed for random forest\n",
        "            # reduce the size of the data for colab\n",
        "            # we will use 10 K rows\n",
        "            # df = df.head(10000)\n",
        "\n",
        "            return df\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Archive '{orc_name}' not found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pq0lCjuQaCLJ"
      },
      "outputs": [],
      "source": [
        "df = prepare_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "czOcJ_7VaCLJ",
        "outputId": "385efc22-a068-4af9-b1d0-128bd666eb0b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cudf.core.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>cudf.core.dataframe.DataFrame</b><br/>def __init__(data=None, index=None, columns=None, dtype=None, copy=None, nan_as_null=no_default)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/cudf/core/dataframe.py</a>A GPU Dataframe object.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "data : array-like, Iterable, dict, or DataFrame.\n",
              "    Dict can contain Series, arrays, constants, or list-like objects.\n",
              "index : Index or array-like\n",
              "    Index to use for resulting frame. Will default to\n",
              "    RangeIndex if no indexing information part of input data and\n",
              "    no index provided.\n",
              "columns : Index or array-like\n",
              "    Column labels to use for resulting frame.\n",
              "    Will default to RangeIndex (0, 1, 2, …, n) if no column\n",
              "    labels are provided.\n",
              "dtype : dtype, default None\n",
              "    Data type to force. Only a single dtype is allowed.\n",
              "    If None, infer.\n",
              "copy : bool or None, default None\n",
              "    Copy data from inputs.\n",
              "    Currently not implemented.\n",
              "nan_as_null : bool, Default True\n",
              "    If ``None``/``True``, converts ``np.nan`` values to\n",
              "    ``null`` values.\n",
              "    If ``False``, leaves ``np.nan`` values as is.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Build dataframe with ``__setitem__``:\n",
              "\n",
              "&gt;&gt;&gt; import cudf\n",
              "&gt;&gt;&gt; df = cudf.DataFrame()\n",
              "&gt;&gt;&gt; df[&#x27;key&#x27;] = [0, 1, 2, 3, 4]\n",
              "&gt;&gt;&gt; df[&#x27;val&#x27;] = [float(i + 10) for i in range(5)]  # insert column\n",
              "&gt;&gt;&gt; df\n",
              "   key   val\n",
              "0    0  10.0\n",
              "1    1  11.0\n",
              "2    2  12.0\n",
              "3    3  13.0\n",
              "4    4  14.0\n",
              "\n",
              "Build DataFrame via dict of columns:\n",
              "\n",
              "&gt;&gt;&gt; import numpy as np\n",
              "&gt;&gt;&gt; from datetime import datetime, timedelta\n",
              "&gt;&gt;&gt; t0 = datetime.strptime(&#x27;2018-10-07 12:00:00&#x27;, &#x27;%Y-%m-%d %H:%M:%S&#x27;)\n",
              "&gt;&gt;&gt; n = 5\n",
              "&gt;&gt;&gt; df = cudf.DataFrame({\n",
              "...     &#x27;id&#x27;: np.arange(n),\n",
              "...     &#x27;datetimes&#x27;: np.array(\n",
              "...     [(t0+ timedelta(seconds=x)) for x in range(n)])\n",
              "... })\n",
              "&gt;&gt;&gt; df\n",
              "    id            datetimes\n",
              "0    0  2018-10-07 12:00:00\n",
              "1    1  2018-10-07 12:00:01\n",
              "2    2  2018-10-07 12:00:02\n",
              "3    3  2018-10-07 12:00:03\n",
              "4    4  2018-10-07 12:00:04\n",
              "\n",
              "Build DataFrame via list of rows as tuples:\n",
              "\n",
              "&gt;&gt;&gt; df = cudf.DataFrame([\n",
              "...     (5, &quot;cats&quot;, &quot;jump&quot;, np.nan),\n",
              "...     (2, &quot;dogs&quot;, &quot;dig&quot;, 7.5),\n",
              "...     (3, &quot;cows&quot;, &quot;moo&quot;, -2.1, &quot;occasionally&quot;),\n",
              "... ])\n",
              "&gt;&gt;&gt; df\n",
              "   0     1     2     3             4\n",
              "0  5  cats  jump  &lt;NA&gt;          &lt;NA&gt;\n",
              "1  2  dogs   dig   7.5          &lt;NA&gt;\n",
              "2  3  cows   moo  -2.1  occasionally\n",
              "\n",
              "Convert from a Pandas DataFrame:\n",
              "\n",
              "&gt;&gt;&gt; import pandas as pd\n",
              "&gt;&gt;&gt; pdf = pd.DataFrame({&#x27;a&#x27;: [0, 1, 2, 3],&#x27;b&#x27;: [0.1, 0.2, None, 0.3]})\n",
              "&gt;&gt;&gt; pdf\n",
              "   a    b\n",
              "0  0  0.1\n",
              "1  1  0.2\n",
              "2  2  NaN\n",
              "3  3  0.3\n",
              "&gt;&gt;&gt; df = cudf.from_pandas(pdf)\n",
              "&gt;&gt;&gt; df\n",
              "   a     b\n",
              "0  0   0.1\n",
              "1  1   0.2\n",
              "2  2  &lt;NA&gt;\n",
              "3  3   0.3</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 947);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "type(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKGb67XWaCLK",
        "outputId": "701618ad-3512-4157-9a45-b4e3035bbb90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ArrDelayBinary 0\n",
            "YEAR 0\n",
            "MONTH 0\n",
            "DAY_OF_MONTH 0\n",
            "DAY_OF_WEEK 0\n",
            "CRS_DEP_TIME 0\n",
            "CRS_ARR_TIME 0\n",
            "OP_UNIQUE_CARRIER 0\n",
            "OP_CARRIER_FL_NUM 0\n",
            "ACTUAL_ELAPSED_TIME 0\n",
            "ORIGIN 0\n",
            "DEST 0\n",
            "DISTANCE 0\n",
            "DIVERTED 0\n"
          ]
        }
      ],
      "source": [
        "# Double check the precesence of Nan\n",
        "for col in df.columns.to_list() :\n",
        "    nan_vals = len ( df[df[col].isna()== True ])\n",
        "    print (col , nan_vals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Phd2OYxaaCLK"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from contextlib import contextmanager\n",
        "# Helping time blocks of code\n",
        "@contextmanager\n",
        "def timed(txt):\n",
        "    t0 = time.time()\n",
        "    yield\n",
        "    t1 = time.time()\n",
        "    print(\"%32s time:  %8.5f\" % (txt, t1 - t0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpXRYjh1aCLK"
      },
      "outputs": [],
      "source": [
        "# Define some default values to make use of across the notebook for a fair comparison\n",
        "N_FOLDS = 3\n",
        "N_ITER = 10  # The number of times that search combinations of parameters\n",
        "SEED = check_random_state(73)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e5XBYSsaCLK"
      },
      "outputs": [],
      "source": [
        "label = 'ArrDelayBinary'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2-8FbijaCLK"
      },
      "source": [
        "## Splitting Data\n",
        "\n",
        "We split the data randomnly into train and test sets using the [cuml train_test_split](https://rapidsai.github.io/projects/cuml/en/0.12.0/api.html#cuml.preprocessing.model_selection.train_test_split) and create CPU versions of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sh-YdszLaCLK"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df, label, test_size=0.2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe2fqN6naCLK"
      },
      "source": [
        "#### Get the data into the CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wj8Q1gPaCLL"
      },
      "outputs": [],
      "source": [
        "X_cpu = X_train.to_pandas()\n",
        "y_cpu = y_train.to_numpy()\n",
        "\n",
        "X_test_cpu = X_test.to_pandas()\n",
        "y_test_cpu = y_test.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZ16w2lDaCLL"
      },
      "source": [
        "## Setup Custom cuML scorers\n",
        "\n",
        "The search functions (such as GridSearchCV) for scikit-learn and dask-ml expect the metric functions (such as accuracy_score) to match the “scorer” API. This can be achieved using the scikit-learn's [make_scorer](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html) function.\n",
        "\n",
        "We will generate a `cuml_scorer` with the cuML `accuracy_score` function.  You'll also notice an `accuracy_score_wrapper` which primarily converts the y label into a `float32` type. This is because some cuML models only accept this type for now and in order to make it compatible, we perform this conversion.\n",
        "\n",
        "We also create helper functions for performing HPO in 2 different modes:\n",
        "1. `gpu-grid`: Perform GPU based GridSearchCV\n",
        "2. `gpu-random`: Perform GPU based RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-jVuQ1YaCLL"
      },
      "outputs": [],
      "source": [
        "def accuracy_score_wrapper(y, y_hat):\n",
        "    \"\"\"\n",
        "        A wrapper function to convert labels to float32,\n",
        "        and pass it to accuracy_score.\n",
        "\n",
        "        Params:\n",
        "        - y: The y labels that need to be converted\n",
        "        - y_hat: The predictions made by the model\n",
        "    \"\"\"\n",
        "    y = y.astype(\"float32\") # cuML RandomForest needs the y labels to be float32\n",
        "    return accuracy_score(y, y_hat, convert_dtype=True)\n",
        "\n",
        "accuracy_wrapper_scorer = make_scorer(accuracy_score_wrapper)\n",
        "cuml_accuracy_scorer = make_scorer(accuracy_score, convert_dtype=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N0a2mHZaCLL"
      },
      "source": [
        "#### This creates a wrapper to help us select the details of the HPO we want to compare and run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ml0aepc6aCLL"
      },
      "outputs": [],
      "source": [
        "def do_HPO(model, gridsearch_params, scorer, X, y, mode='gpu-Grid', n_iter=10):\n",
        "    \"\"\"\n",
        "        Perform HPO based on the mode specified\n",
        "\n",
        "        mode: default gpu-Grid. The possible options are:\n",
        "        1. gpu-grid: Perform GPU based GridSearchCV\n",
        "        2. gpu-random: Perform GPU based RandomizedSearchCV\n",
        "\n",
        "        n_iter: specified with Random option for number of parameter settings sampled\n",
        "\n",
        "        Returns the best estimator and the results of the search\n",
        "    \"\"\"\n",
        "    if mode == 'gpu-grid':\n",
        "        print(\"gpu-grid selected\")\n",
        "        clf = GridSearchCV(model,\n",
        "                               gridsearch_params,\n",
        "                               cv=N_FOLDS,\n",
        "                               scoring=scorer)\n",
        "    elif mode == 'gpu-random':\n",
        "        print(\"gpu-random selected\")\n",
        "        clf = RandomizedSearchCV(model,\n",
        "                               gridsearch_params,\n",
        "                               cv=N_FOLDS,\n",
        "                               scoring=scorer,\n",
        "                               n_iter=n_iter)\n",
        "\n",
        "    else:\n",
        "        print(\"Unknown Option, please choose one of [gpu-grid, gpu-random]\")\n",
        "        return None, None\n",
        "    res = clf.fit(X, y)\n",
        "    print(\"Best clf and score {} {}\\n---\\n\".format(res.best_estimator_, res.best_score_))\n",
        "    return res.best_estimator_, res"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48b10855"
      },
      "source": [
        "\n",
        "\n",
        "def manual_random_search_xgb(model, param_distributions, X, y, n_iter=10, n_splits=N_FOLDS, random_state=SEED):\n",
        "    \"\"\"\n",
        "    Performs manual randomized search cross-validation for XGBoost using KFold.\n",
        "\n",
        "    Args:\n",
        "        model: The cuML/XGBoost model to train.\n",
        "        param_distributions: Dictionary with parameters names (string) as keys and distributions\n",
        "            or lists of parameters to sample from as values.\n",
        "        X: cuDF DataFrame of features.\n",
        "        y: cuDF Series of labels.\n",
        "        n_iter: Number of parameter settings that are sampled.\n",
        "        n_splits: Number of folds for cross-validation.\n",
        "        random_state: Random state for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing the best estimator and a dictionary of results.\n",
        "    \"\"\"\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    param_sampler = ParameterSampler(param_distributions, n_iter=n_iter, random_state=random_state)\n",
        "\n",
        "    best_score = -float('inf')\n",
        "    best_params = None\n",
        "    cv_results = []\n",
        "\n",
        "    # Need to compute the splits once as they are dask delayed objects\n",
        "    splits = list(kf.split(X))\n",
        "\n",
        "    for i, params in enumerate(param_sampler):\n",
        "        print(f\"Fitting iteration {i+1}/{n_iter} with parameters: {params}\")\n",
        "        fold_scores = []\n",
        "\n",
        "        for fold_idx, (train_idx, val_idx) in enumerate(splits):\n",
        "            # Use cuDF indexing with computed indices\n",
        "            # Compute the indices once per iteration to avoid recomputing in each fold\n",
        "            train_idx_computed = train_idx\n",
        "            val_idx_computed = val_idx\n",
        "\n",
        "            X_train_fold = X.iloc[train_idx_computed]\n",
        "            y_train_fold = y.iloc[train_idx_computed]\n",
        "            X_val_fold = X.iloc[val_idx_computed]\n",
        "            y_val_fold = y.iloc[val_idx_computed]\n",
        "\n",
        "            # Ensure y is float32 for cuML\n",
        "            y_train_fold = y_train_fold.astype('float32')\n",
        "            y_val_fold = y_val_fold.astype('float32')\n",
        "\n",
        "\n",
        "            # Train the model with current parameters\n",
        "            current_model = model.set_params(**params)\n",
        "            current_model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "            # Evaluate on the validation fold\n",
        "            y_pred_fold = current_model.predict(X_val_fold)\n",
        "            score = accuracy_score(y_val_fold, y_pred_fold)\n",
        "            fold_scores.append(score)\n",
        "\n",
        "        mean_score = np.mean(fold_scores)\n",
        "        cv_results.append({'params': params, 'mean_test_score': mean_score, 'fold_scores': fold_scores})\n",
        "\n",
        "        if mean_score > best_score:\n",
        "            best_score = mean_score\n",
        "            best_params = params\n",
        "            # Store the best estimator found during CV (optional, but can be useful)\n",
        "            best_cv_estimator = current_model\n",
        "\n",
        "\n",
        "    print(\"\\n---\")\n",
        "    print(f\"Best parameters found: {best_params}\")\n",
        "    print(f\"Best cross-validation score: {best_score}\")\n",
        "    print(\"---\")\n",
        "\n",
        "    # Train the final model on the full training data with best params\n",
        "    final_model = model.set_params(**best_params)\n",
        "    final_model.fit(X, y.astype('float32')) # Ensure y is float32 for final training\n",
        "\n",
        "    results_dict = {\n",
        "        'best_estimator_': final_model,\n",
        "        'best_score_': best_score,\n",
        "        'best_params_': best_params,\n",
        "        'cv_results_': cv_results\n",
        "    }\n",
        "\n",
        "    return final_model, results_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGMLjuLmaCLL"
      },
      "outputs": [],
      "source": [
        "def print_acc(model, X_train, y_train, X_test, y_test, mode_str=\"Default\"):\n",
        "    \"\"\"\n",
        "        Trains a model on the train data provided, and prints the accuracy of the trained model.\n",
        "        mode_str: User specifies what model it is to print the value\n",
        "    \"\"\"\n",
        "    y_pred = model.fit(X_train, y_train).predict(X_test)\n",
        "    score = accuracy_score(y_pred, y_test.astype('float32'))\n",
        "    print(\"{} model accuracy: {}\".format(mode_str, score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMtc_cGxaCLL"
      },
      "source": [
        "#### Look at trainin set shape, we are going to read 200k rows and 13 columns as features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKWfITTuaCLL",
        "outputId": "cd0d4d37-b414-437e-e0dc-32e23052a809"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000000, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoB-8gZzaCLM"
      },
      "source": [
        "## Launch HPO\n",
        "\n",
        "We will first see the model's performances without the gridsearch and then compare it with the performance after searching.\n",
        "\n",
        "### XGBoost\n",
        "\n",
        "To perform the Hyperparameter Optimization, we make use of the sklearn version of the [XGBClassifier](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn).We're making use of this version to make it compatible and easily comparable to the scikit-learn version. The model takes a set of parameters that can be found in the documentation. We're primarily interested in the `max_depth`, `learning_rate`, `min_child_weight`, `reg_alpha` and `num_round` as these affect the performance of XGBoost the most.\n",
        "\n",
        "Read more about what these parameters are useful for [here](https://xgboost.readthedocs.io/en/latest/parameter.html)\n",
        "\n",
        "#### Default Performance\n",
        "\n",
        "We first use the model with it's default parameters and see the accuracy of the model. In this case, it is 84%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yriOoj6aCLM",
        "outputId": "8d4b909c-2834-41be-a70d-80a47544c134"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default model accuracy: 0.848312\n"
          ]
        }
      ],
      "source": [
        "model_gpu_xgb_ = xgb.XGBClassifier(tree_method='hist',device = 'cuda',random_state=SEED)\n",
        "print_acc(model_gpu_xgb_, X_train, y_cpu, X_test, y_test_cpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vJ98HDLaCLM"
      },
      "outputs": [],
      "source": [
        "# ## Random Forest\n",
        "# model_rf_ = RandomForestClassifier()\n",
        "\n",
        "# print(\"Default acc: \",accuracy_score(model_rf_.fit(X_train, y_train).predict(X_test), y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuDWYRy4aCLM"
      },
      "source": [
        "#### Lets define a set of parameters to explore with model of interest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYjjydPuaCLM"
      },
      "outputs": [],
      "source": [
        "# # For rf_model\n",
        "# model_rf = RandomForestClassifier()\n",
        "\n",
        "# # range\n",
        "# params_rf = {\n",
        "#     \"max_depth\": np.arange(start=3, stop = 15, step = 2), # Default = 6\n",
        "#     \"max_features\": [0.1, 0.50, 0.75, 'auto'], #default = 0.3\n",
        "#     \"n_estimators\": [100, 200, 1000]\n",
        "#             }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nt2iMSJQaCLM"
      },
      "source": [
        "#### Parameter Distributions\n",
        "\n",
        "The way we define the grid to perform the search is by including ranges of parameters that need to be used for the search. In this example we make use of [np.arange](https://docs.scipy.org/doc/numpy/reference/generated/numpy.arange.html) which returns an ndarray of even spaced values, [np.logspace](https://docs.scipy.org/doc/numpy/reference/generated/numpy.logspace.html#numpy.logspace) returns a specified number of ssamples that are equally spaced on the log scale. We can also specify as lists, NumPy arrays or make use of any random variate sample that gives a sample when called. SciPy provides various functions for this too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMVjdORJaCLM"
      },
      "outputs": [],
      "source": [
        "# For xgb_model\n",
        "model_gpu_xgb = xgb.XGBClassifier(tree_method='hist',device = 'cuda',random_state=SEED)\n",
        "\n",
        "# More range\n",
        "params_xgb = {\n",
        "    \"max_depth\": np.arange(start=3, stop = 12, step = 3), # Default = 6\n",
        "    \"alpha\" : np.logspace(-3, -1, 5), # default = 0\n",
        "    \"learning_rate\": [0.05, 0.1, 0.15], #default = 0.3\n",
        "    \"min_child_weight\" : np.arange(start=2, stop=10, step=3), # default = 1\n",
        "    \"n_estimators\": [100, 200, 1000]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHxu-ZzQaCLM"
      },
      "source": [
        "#### RandomizedSearchCV\n",
        "\n",
        "We'll now try [RandomizedSearchCV](https://dask-ml.readthedocs.io/en/latest/modules/generated/dask_ml.model_selection.RandomizedSearchCV.html).\n",
        "`n_iter` specifies the number of parameters points theat the search needs to perform. Here we will search `N_ITER` (defined earlier) points for the best performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnOgeSbvaCLM",
        "outputId": "1ad8f647-3890-4ee2-ba8e-da8da334bc13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting iteration 1/10 with parameters: {'n_estimators': 1000, 'min_child_weight': np.int64(5), 'max_depth': np.int64(3), 'learning_rate': 0.05, 'alpha': np.float64(0.03162277660168379)}\n",
            "Fitting iteration 2/10 with parameters: {'n_estimators': 200, 'min_child_weight': np.int64(8), 'max_depth': np.int64(3), 'learning_rate': 0.15, 'alpha': np.float64(0.03162277660168379)}\n",
            "Fitting iteration 3/10 with parameters: {'n_estimators': 100, 'min_child_weight': np.int64(2), 'max_depth': np.int64(6), 'learning_rate': 0.05, 'alpha': np.float64(0.001)}\n",
            "Fitting iteration 4/10 with parameters: {'n_estimators': 100, 'min_child_weight': np.int64(8), 'max_depth': np.int64(6), 'learning_rate': 0.05, 'alpha': np.float64(0.1)}\n",
            "Fitting iteration 5/10 with parameters: {'n_estimators': 1000, 'min_child_weight': np.int64(2), 'max_depth': np.int64(9), 'learning_rate': 0.15, 'alpha': np.float64(0.03162277660168379)}\n",
            "Fitting iteration 6/10 with parameters: {'n_estimators': 100, 'min_child_weight': np.int64(8), 'max_depth': np.int64(3), 'learning_rate': 0.15, 'alpha': np.float64(0.03162277660168379)}\n",
            "Fitting iteration 7/10 with parameters: {'n_estimators': 100, 'min_child_weight': np.int64(2), 'max_depth': np.int64(3), 'learning_rate': 0.15, 'alpha': np.float64(0.01)}\n",
            "Fitting iteration 8/10 with parameters: {'n_estimators': 1000, 'min_child_weight': np.int64(8), 'max_depth': np.int64(6), 'learning_rate': 0.1, 'alpha': np.float64(0.0031622776601683794)}\n",
            "Fitting iteration 9/10 with parameters: {'n_estimators': 200, 'min_child_weight': np.int64(5), 'max_depth': np.int64(9), 'learning_rate': 0.1, 'alpha': np.float64(0.03162277660168379)}\n",
            "Fitting iteration 10/10 with parameters: {'n_estimators': 1000, 'min_child_weight': np.int64(5), 'max_depth': np.int64(6), 'learning_rate': 0.15, 'alpha': np.float64(0.1)}\n",
            "\n",
            "---\n",
            "Best parameters found: {'n_estimators': 1000, 'min_child_weight': np.int64(2), 'max_depth': np.int64(9), 'learning_rate': 0.15, 'alpha': np.float64(0.03162277660168379)}\n",
            "Best cross-validation score: 0.8634234999391817\n",
            "---\n",
            "       XGB-manual-gpu-random-xgb time:  137.07680\n"
          ]
        }
      ],
      "source": [
        "mode = \"manual-gpu-random-xgb\"\n",
        "\n",
        "with timed(\"XGB-\"+mode):\n",
        "    # Use the manual random search function\n",
        "    res, results = manual_random_search_xgb(model_gpu_xgb,\n",
        "                                   params_xgb,\n",
        "                                   X_train, # Pass cuDF DataFrame\n",
        "                                   y_train, # Pass cuDF Series\n",
        "                                   n_iter=N_ITER,\n",
        "                                   n_splits=N_FOLDS,\n",
        "                                   random_state=SEED)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRpSjDUOaCLM",
        "outputId": "34c6cda3-d21a-4491-8e80-cec2504d023a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default model accuracy: 0.848312\n",
            "manual-gpu-random-xgb model accuracy: 0.866868\n"
          ]
        }
      ],
      "source": [
        "print_acc(model_gpu_xgb_, X_train, y_cpu, X_test, y_test_cpu)\n",
        "print_acc(res, X_train, y_cpu, X_test, y_test_cpu, mode_str=mode)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mode = \"gpu-random\"\n",
        "\n",
        "with timed(\"XGB-\"+mode):\n",
        "    res, results = do_HPO(model_gpu_xgb,\n",
        "                                   params_xgb,\n",
        "                                   cuml_accuracy_scorer,\n",
        "                                   X_train,\n",
        "                                   y_cpu,\n",
        "                                   mode=mode,\n",
        "                                   n_iter=N_ITER)\n",
        "print(\"Searched over {} parameters\".format(len(results.cv_results_['mean_test_score'])))"
      ],
      "metadata": {
        "id": "Z__uDWuxCUbN",
        "outputId": "6d511a41-9d1c-4d7b-e8c8-132e634f813f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpu-random selected\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/distributed/client.py:3363: UserWarning: Sending large graph of size 144.08 MiB.\n",
            "This may cause some slowdown.\n",
            "Consider loading the data with Dask directly\n",
            " or using futures or delayed objects to embed the data into the graph without repetition.\n",
            "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
            "  warnings.warn(\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 3, 0) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 2, 1) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 6, 2) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 3, 0) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 2, 1) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 6, 2) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 3, 0) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 2, 1) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 6, 2) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 3, 0) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 2, 1) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 6, 2) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 3, 0) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 2, 1) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 6, 2) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 3, 0) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 2, 1) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 6, 2) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 3, 0) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 2, 1) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 6, 2) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 3, 0) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 2, 1) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 6, 2) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 3, 0) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 2, 1) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 6, 2) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 3, 0) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 2, 1) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 6, 2) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 3, 0) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 2, 1) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 6, 2) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 3, 0) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 2, 1) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 6, 2) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 3, 0) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 2, 1) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 6, 2) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 3, 0) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 2, 1) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 6, 2) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 3, 0) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-b2d22fcccd03d3699430ac5342e819a8', 2, 1) has failed... retrying\n",
            "INFO:distributed.scheduler:Client Client-05e436a4-785c-11f0-bf10-0242ac1c000c requests to retry 1 keys\n",
            "INFO:distributed.nanny:Closing Nanny gracefully at 'ucx://127.0.0.1:44513'. Reason: worker-close\n",
            "INFO:distributed.core:Received 'close-stream' from ucx://127.0.0.1:46715; closing.\n",
            "INFO:distributed.scheduler:Remove worker addr: ucx://127.0.0.1:51181 name: 0 (stimulus_id='handle-worker-cleanup-1755100134.008085')\n",
            "WARNING:distributed.scheduler:Removing worker 'ucx://127.0.0.1:51181' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'cv-split-b2d22fcccd03d3699430ac5342e819a8', 'cv-n-samples-b2d22fcccd03d3699430ac5342e819a8', 'DataFrame-16c07432363c07b4bd748dce21014cb1', 'xgbclassifier-b2d22fcccd03d3699430ac5342e819a8', 'ndarray-c03ce7aee51abdade3f9b18b47608ce4'} (stimulus_id='handle-worker-cleanup-1755100134.008085')\n",
            "INFO:distributed.scheduler:Lost all workers\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4293627629.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtimed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"XGB-\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     res, results = do_HPO(model_gpu_xgb,\n\u001b[0m\u001b[1;32m      5\u001b[0m                                    \u001b[0mparams_xgb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                    \u001b[0mcuml_accuracy_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3182622370.py\u001b[0m in \u001b[0;36mdo_HPO\u001b[0;34m(model, gridsearch_params, scorer, X, y, mode, n_iter)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown Option, please choose one of [gpu-grid, gpu-random]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best clf and score {} {}\\n---\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dask_ml/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m   1270\u001b[0m             \u001b[0mresult_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m             \u001b[0mac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_completed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1272\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1273\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"finished\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/distributed/client.py\u001b[0m in \u001b[0;36mbatches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5980\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5981\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5982\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5983\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5984\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/distributed/client.py\u001b[0m in \u001b[0;36mnext_batch\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   5952\u001b[0m         \"\"\"\n\u001b[1;32m   5953\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5954\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5955\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5956\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/distributed/client.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5908\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5909\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread_condition\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5910\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5911\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_and_raise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5-62cbFaCLM"
      },
      "source": [
        "#### XgBoost improves\n",
        "With a very small set of parameter and with a random search we have a 0.863 accuracy vs 0.848 baseline accuracy a gain of 1% in about 2 minutes of testing, not bad. The main target for HPO is to explore wider ranges of parameters and usually with more data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4YyxxppaCLM"
      },
      "outputs": [],
      "source": [
        "# mode = \"gpu-random\"\n",
        "\n",
        "# with timed(\"RF-\"+mode):\n",
        "#     res, results = do_HPO(model_rf,\n",
        "#                           params_rf,\n",
        "#                           cuml_accuracy_scorer,\n",
        "#                           X_train.to_cupy().get(),\n",
        "#                           y_cpu,\n",
        "#                           mode=mode,\n",
        "#                          n_iter = N_ITER)\n",
        "# print(\"Searched over {} parameters\".format(len(results.cv_results_['mean_test_score'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5vEtTplaCLN"
      },
      "outputs": [],
      "source": [
        "# print(\"Improved acc: \",accuracy_score(res.predict(X_test), y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WOx8XjsaCLS"
      },
      "source": [
        "#### Heatmaps\n",
        "   - Between parameter pairs (we can do a combination of all possible pairs, but only one are shown in this notebook)\n",
        "   - This gives a visual representation of how the pair affect the test score"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q-_mbumAAI5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results.get(\"cv_results_\")[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HIoj6E2-vUa",
        "outputId": "8d6d12cf-1af8-49a6-9573-c8851f05afdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'params': {'n_estimators': 100,\n",
              "  'min_child_weight': np.int64(2),\n",
              "  'max_depth': np.int64(6),\n",
              "  'learning_rate': 0.05,\n",
              "  'alpha': np.float64(0.1)},\n",
              " 'mean_test_score': np.float64(0.8326195000000001),\n",
              " 'fold_scores': [0.8331525, 0.8314175, 0.832685, 0.83334, 0.8325025]}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "6c1vgyB7aCLS",
        "outputId": "90eced2d-3148-49cf-8864-ccb5d28053ba"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unhashable type: 'list'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2974538741.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_randomsearch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cv_results_\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# plotting_utils.plot_heatmap(df_randomsearch, \"max_depth\", \"n_estimators\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
          ]
        }
      ],
      "source": [
        "df_randomsearch = pd.DataFrame(results[[\"cv_results_\"],[\"params\"]])\n",
        "# plotting_utils.plot_heatmap(df_randomsearch, \"max_depth\", \"n_estimators\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_randomsearch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gsMJK9vp_NKW",
        "outputId": "14d9cd05-0630-43a5-b992-34cdcac0bedd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              params  mean_test_score  \\\n",
              "0  {'n_estimators': 100, 'min_child_weight': 2, '...         0.832620   \n",
              "1  {'n_estimators': 200, 'min_child_weight': 5, '...         0.833179   \n",
              "2  {'n_estimators': 1000, 'min_child_weight': 8, ...         0.844618   \n",
              "3  {'n_estimators': 200, 'min_child_weight': 5, '...         0.825242   \n",
              "4  {'n_estimators': 100, 'min_child_weight': 8, '...         0.844419   \n",
              "\n",
              "                                         fold_scores  \n",
              "0  [0.8331525, 0.8314175, 0.832685, 0.83334, 0.83...  \n",
              "1   [0.8326, 0.8335475, 0.83363, 0.83281, 0.8333075]  \n",
              "2  [0.84393, 0.845065, 0.8442675, 0.8446175, 0.84...  \n",
              "3    [0.82563, 0.8256275, 0.8253, 0.82478, 0.824875]  \n",
              "4  [0.84439, 0.8437175, 0.8437625, 0.8449325, 0.8...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-155313c6-908a-4ab4-b112-9860aa3f5557\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>params</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>fold_scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'n_estimators': 100, 'min_child_weight': 2, '...</td>\n",
              "      <td>0.832620</td>\n",
              "      <td>[0.8331525, 0.8314175, 0.832685, 0.83334, 0.83...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'n_estimators': 200, 'min_child_weight': 5, '...</td>\n",
              "      <td>0.833179</td>\n",
              "      <td>[0.8326, 0.8335475, 0.83363, 0.83281, 0.8333075]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'n_estimators': 1000, 'min_child_weight': 8, ...</td>\n",
              "      <td>0.844618</td>\n",
              "      <td>[0.84393, 0.845065, 0.8442675, 0.8446175, 0.84...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'n_estimators': 200, 'min_child_weight': 5, '...</td>\n",
              "      <td>0.825242</td>\n",
              "      <td>[0.82563, 0.8256275, 0.8253, 0.82478, 0.824875]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'n_estimators': 100, 'min_child_weight': 8, '...</td>\n",
              "      <td>0.844419</td>\n",
              "      <td>[0.84439, 0.8437175, 0.8437625, 0.8449325, 0.8...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-155313c6-908a-4ab4-b112-9860aa3f5557')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-155313c6-908a-4ab4-b112-9860aa3f5557 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-155313c6-908a-4ab4-b112-9860aa3f5557');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d8eba16b-cb3b-473b-90a0-b343d7209580\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d8eba16b-cb3b-473b-90a0-b343d7209580')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d8eba16b-cb3b-473b-90a0-b343d7209580 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_fa95751e-5a99-4729-af1f-a038f6023b5b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_randomsearch')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fa95751e-5a99-4729-af1f-a038f6023b5b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_randomsearch');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_randomsearch",
              "summary": "{\n  \"name\": \"df_randomsearch\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"params\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_test_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008370455411744367,\n        \"min\": 0.8252424999999999,\n        \"max\": 0.8446184999999999,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.833179,\n          0.8444185000000001,\n          0.8446184999999999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fold_scores\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xSzpn51aCLS"
      },
      "source": [
        "### Now lets perfrom the Grid-search strategy. This will explore all the the possible combinations , we should skip this for the sake of time (takes about 1 hrs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3_ch2jLaCLS"
      },
      "outputs": [],
      "source": [
        "mode = \"gpu-grid\"\n",
        "\n",
        "# For xgb_model\n",
        "model_gpu_xgb = xgb.XGBClassifier(tree_method='gpu_hist',random_state=SEED)\n",
        "\n",
        "with timed(\"XGB-\"+mode):\n",
        "    res, results = do_HPO(model_gpu_xgb,\n",
        "                            params_xgb,\n",
        "                                   cuml_accuracy_scorer,\n",
        "                                   X_train,\n",
        "                                   y_cpu,\n",
        "                                   mode=mode)\n",
        "print(\"Searched over {} parameters\".format(len(results.cv_results_['mean_test_score'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDikalh7aCLT"
      },
      "outputs": [],
      "source": [
        "# mode = \"gpu-grid\"\n",
        "\n",
        "# # For rf_model\n",
        "# model_rf = RandomForestClassifier()\n",
        "\n",
        "# with timed(\"RF-\"+mode):\n",
        "#     res, results = do_HPO(model_rf,\n",
        "#                           params_rf,\n",
        "#                           cuml_accuracy_scorer,\n",
        "#                           X_train.to_cupy().get(),\n",
        "#                           y_cpu,\n",
        "#                           mode=mode,\n",
        "#                          n_iter = N_ITER)\n",
        "# print(\"Searched over {} parameters\".format(len(results.cv_results_['mean_test_score'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhwjNDUvaCLT"
      },
      "outputs": [],
      "source": [
        "print_acc(model_gpu_xgb_, X_train, y_cpu, X_test, y_test_cpu)\n",
        "print_acc(res, X_train, y_cpu, X_test, y_test_cpu, mode_str=mode)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6suf92JfaCLT"
      },
      "source": [
        "#### We have run the classifiers with two strategies its up to you decide which one is the best\n",
        "* **Xgboost baseline accuracy is 0.848**\n",
        "* **Xgboost with Random search is 0.869 accuracy -> 5 minutes**\n",
        "* **Xgboost with Grid search is 0.866 accuracy  -> 1 hour**\n",
        "\n",
        "#### Mean/Std of test scores\n",
        "\n",
        "We fix all parameters except one for each of these graphs and plot the effect the parameter has on the mean test score with the error bar indicating the standard deviation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEnjTrLnaCLT"
      },
      "outputs": [],
      "source": [
        "plotting_utils.plot_search_results(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6hGhApjaCLT"
      },
      "outputs": [],
      "source": [
        "df_gridsearch = pd.DataFrame(results.cv_results_)\n",
        "plotting_utils.plot_heatmap(df_gridsearch, \"param_max_depth\", \"param_n_estimators\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fv2u8eaaCLT"
      },
      "source": [
        "## Conclusion and Next Steps\n",
        "\n",
        "We notice improvements in the performance for a really basic version of the GridSearch and RandomizedSearch. Generally, the more data we use, the better the model performs, so you are encouraged to try for larger data and broader range of parameters.\n",
        "\n",
        "This experiment can also be repeated with different classifiers and different ranges of parameters to notice how HPO can help improve the performance metric. In this example, we have chosen a basic metric - accuracy, but you can use more interesting metrics that help in determining the usefulness of a model. You can even send a list of parameters to the scoring function. This makes HPO really powerful, and it can add a significant boost to the model that we generate.\n",
        "\n",
        "\n",
        "#### Further Reading\n",
        "\n",
        "- [The 5 Classification Evaluation Metrics You Must Know](https://towardsdatascience.com/the-5-classification-evaluation-metrics-you-must-know-aa97784ff226)\n",
        "- [11 Important Model Evaluation Metrics for Machine Learning Everyone should know](https://www.analyticsvidhya.com/blog/2019/08/11-important-model-evaluation-error-metrics/)\n",
        "- [Algorithms for Hyper-Parameter Optimisation](http://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf)\n",
        "- [Forward and Reverse Gradient-Based Hyperparameter Optimization](http://proceedings.mlr.press/v70/franceschi17a/franceschi17a-supp.pdf)\n",
        "- [Practical Bayesian Optimization of Machine\n",
        "Learning Algorithms](http://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf)\n",
        "- [Random Search for Hyper-Parameter Optimization](http://jmlr.csail.mit.edu/papers/volume13/bergstra12a/bergstra12a.pdf)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}